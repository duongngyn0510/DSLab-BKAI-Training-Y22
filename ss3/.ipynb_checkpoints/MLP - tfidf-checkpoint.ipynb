{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310aeb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b198e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path = \"./datasets\"):\n",
    "    # Get data from each line with label, doc_id, index & tfidf of its vocab\n",
    "    def sparse_to_dense(sparse_r_d, vocab_size):\n",
    "        # Init list size vocal size to store vocal \n",
    "        r_d = [0.0 for _ in range(vocab_size)]\n",
    "            \n",
    "        # Split space & : in context data of each line \n",
    "        # Get index (id vocal of each line) & tfidfs\n",
    "        indices_and_tfidfs = sparse_r_d.split()\n",
    "        for index_and_tfidf in indices_and_tfidfs:\n",
    "            index = int(index_and_tfidf.split(':')[0])\n",
    "            tfidf = float(index_and_tfidf.split(':')[1])\n",
    "            r_d[index] = tfidf\n",
    "        return np.array(r_d)    \n",
    "                \n",
    "    # Open file (newsgroup, id, context)\n",
    "    with open(os.path.join(path, \"data_tf_idf.txt\")) as f:\n",
    "        data_lines = f.read().splitlines()\n",
    "    # Get size file vocal TF-IDF\n",
    "    with open(os.path.join(path, \"words_idfs.txt\")) as f:\n",
    "        vocab_size = len(f.read().splitlines())\n",
    "\n",
    "    # Member store info of data points: tf_idf, news group, file name of text d\n",
    "    data, labels = [], []\n",
    "    # Iterating sequence of pairs with counter\n",
    "    for data_id, d in enumerate(data_lines):\n",
    "        features = d.split('<fff>')\n",
    "        label, doc_id = int(features[0]), int(features[1])\n",
    "        r_d = sparse_to_dense(sparse_r_d=features[2], vocab_size=vocab_size)\n",
    "\n",
    "        # Append data & labels\n",
    "        data.append(r_d)\n",
    "        labels.append(label)\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd679b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = load_data()\n",
    "\n",
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089d10d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14230)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                910784    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 913,524\n",
      "Trainable params: 913,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(X_train.shape[1:]))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "outputs = layers.Dense(20, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56f86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                  mode='max',\n",
    "                                                  verbose=1,\n",
    "                                                  patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d50b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 3s 5ms/step - loss: 1.7889 - accuracy: 0.6089 - val_loss: 0.6989 - val_accuracy: 0.8655\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.3341 - accuracy: 0.9367 - val_loss: 0.4136 - val_accuracy: 0.8936\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.1025 - accuracy: 0.9856 - val_loss: 0.3813 - val_accuracy: 0.8917\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9961 - val_loss: 0.3749 - val_accuracy: 0.8949\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9984 - val_loss: 0.3812 - val_accuracy: 0.8936\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.3776 - val_accuracy: 0.8944\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.3932 - val_accuracy: 0.8931\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.3992 - val_accuracy: 0.8915\n",
      "Epoch 9/20\n",
      "344/354 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9992Restoring model weights from the end of the best epoch: 4.\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.4065 - val_accuracy: 0.8891\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compile and fit model\n",
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer = \"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs = 20,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea42c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3790754973888397, 0.8920424580574036]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade97c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict newsgroup\n",
    "np.argmax(model.predict(X_test[:1]), axis= -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
